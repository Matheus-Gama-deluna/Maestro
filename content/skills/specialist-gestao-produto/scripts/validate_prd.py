#!/usr/bin/env python3
"""
Script de Valida√ß√£o de PRD - Maestro Skills
Valida qualidade e completude do PRD baseado no checklist
"""

import os
import sys
import argparse
import re
from pathlib import Path
from datetime import datetime

class PRDValidator:
    def __init__(self, base_dir=None):
        self.base_dir = Path(base_dir) if base_dir else Path(__file__).parent.parent
        self.prd_path = self.base_dir / "docs" / "01-produto" / "PRD.md"
        self.checklist_path = self.base_dir / "resources" / "checklists" / "prd-validation.md"
        self.min_score = 70
        
    def load_prd(self):
        """Carrega conte√∫do do PRD"""
        try:
            with open(self.prd_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"‚ùå PRD n√£o encontrado: {self.prd_path}")
            sys.exit(1)
            
    def load_checklist(self):
        """Carrega checklist de valida√ß√£o"""
        try:
            with open(self.checklist_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"‚ùå Checklist n√£o encontrado: {self.checklist_path}")
            sys.exit(1)
            
    def count_checkboxes(self, content):
        """Conta checkboxes marcados e totais"""
        checked = len(re.findall(r'- \[x\]', content, re.IGNORECASE))
        total = len(re.findall(r'- \[[ x]\]', content))
        return checked, total
        
    def validate_problem_section(self, content):
        """Valida se√ß√£o de Problema e Oportunidade"""
        score = 0
        feedback = []
        
        # Problema claro e espec√≠fico
        if re.search(r'Problema.*claro.*espec√≠fico', content):
            score += 3
        else:
            feedback.append("‚ùå Problema n√£o est√° claro ou espec√≠fico")
            
        # Impacto quantific√°vel
        if re.search(r'\d+%|\d+x|\$\d+', content):
            score += 3
        else:
            feedback.append("‚ùå Impacto n√£o est√° quantificado")
            
        # Causa raiz
        if re.search(r'causa.*raiz|root cause', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Causa raiz n√£o identificada")
            
        # Oportunidade
        if re.search(r'oportunidade.*mercado|market.*opportunity', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Oportunidade de mercado n√£o clara")
            
        # Timing
        if re.search(r'timing|agora.*momento|why now', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Timing n√£o justificado")
            
        return score, feedback
        
    def validate_personas_section(self, content):
        """Valida se√ß√£o de Personas e JTBD"""
        score = 0
        feedback = []
        
        # Conta personas
        personas = re.findall(r'### \d+\.\d+ Persona', content)
        if len(personas) >= 2:
            score += 5
        else:
            feedback.append(f"‚ùå Apenas {len(personas)} persona(s) encontradas (m√≠nimo 2)")
            
        # JTBD mapeados
        if re.search(r'Jobs to Be Done|JTBD', content, re.IGNORECASE):
            score += 5
        else:
            feedback.append("‚ùå Jobs to Be Done n√£o mapeados")
            
        # Dores e ganhos
        if re.search(r'Dores.*Ganhos|Pains.*Gains', content, re.IGNORECASE):
            score += 5
        else:
            feedback.append("‚ùå Dores e ganhos n√£o especificados")
            
        return score, feedback
        
    def validate_north_star(self, content):
        """Valida North Star Metric"""
        score = 0
        feedback = []
        
        # North Star definida
        if re.search(r'North Star.*definida|North Star Metric', content, re.IGNORECASE):
            score += 4
        else:
            feedback.append("‚ùå North Star Metric n√£o definida")
            
        # Mensur√°vel
        if re.search(r'como medir|how to measure', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå North Star n√£o √© mensur√°vel")
            
        # Reflete valor
        if re.search(r'reflete.*valor|valor.*usu√°rio', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå North Star n√£o reflete valor real")
            
        return score, feedback
        
    def validate_mvp_section(self, content):
        """Valida se√ß√£o de MVP"""
        score = 0
        feedback = []
        
        # Funcionalidades priorizadas
        functionalities = re.findall(r'Funcionalidade \d+:', content)
        if 3 <= len(functionalities) <= 5:
            score += 5
        else:
            feedback.append(f"‚ùå {len(functionalities)} funcionalidades (ideal: 3-5)")
            
        # Matriz RICE
        if re.search(r'RICE.*Score|Reach.*Impact.*Confidence.*Effort', content, re.IGNORECASE):
            score += 5
        else:
            feedback.append("‚ùå Matriz RICE n√£o preenchida")
            
        # Fora do escopo
        if re.search(r'Fora.*escopo|Out of scope', content, re.IGNORECASE):
            score += 5
        else:
            feedback.append("‚ùå Fora do escopo n√£o definido")
            
        return score, feedback
        
    def validate_metrics_section(self, content):
        """Valida se√ß√£o de M√©tricas"""
        score = 0
        feedback = []
        
        # KPIs secund√°rios
        kpis = re.findall(r'KPI \d+:', content)
        if len(kpis) >= 2:
            score += 4
        else:
            feedback.append("‚ùå KPIs secund√°rios insuficientes")
            
        # M√©tricas anti-vanity
        if re.search(r'anti.*vanity|real.*metrics', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå M√©tricas anti-vanity n√£o inclu√≠das")
            
        # Metas espec√≠ficas
        if re.search(r'meta.*\d+|target.*\d+', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Metas n√£o espec√≠ficas")
            
        return score, feedback
        
    def validate_risks_section(self, content):
        """Valida se√ß√£o de Riscos"""
        score = 0
        feedback = []
        
        # Riscos t√©cnicos
        if re.search(r'Risco.*t√©cnico|technical.*risk', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Riscos t√©cnicos n√£o identificados")
            
        # Riscos de neg√≥cio
        if re.search(r'Risco.*neg√≥cio|business.*risk', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Riscos de neg√≥cio n√£o identificados")
            
        # Planos de mitiga√ß√£o
        if re.search(r'plano.*mitiga√ß√£o|mitigation.*plan', content, re.IGNORECASE):
            score += 4
        else:
            feedback.append("‚ùå Planos de mitiga√ß√£o espec√≠ficos")
            
        return score, feedback
        
    def validate_timeline_section(self, content):
        """Valida se√ß√£o de Timeline"""
        score = 0
        feedback = []
        
        # Timeline realista
        if re.search(r'6.*8.*semanas|6.*8.*weeks', content, re.IGNORECASE):
            score += 4
        else:
            feedback.append("‚ùå Timeline n√£o realista (deve ser 6-8 semanas)")
            
        # Marcos cr√≠ticos
        milestones = re.findall(r'Marco \d+:', content)
        if len(milestones) >= 2:
            score += 3
        else:
            feedback.append("‚ùå Marcos cr√≠ticos insuficientes")
            
        # Recursos mapeados
        if re.search(r'Recursos.*necess√°rios|resources.*needed', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Recursos n√£o mapeados")
            
        return score, feedback
        
    def validate_quality_section(self, content):
        """Valida se√ß√£o de Qualidade"""
        score = 0
        feedback = []
        
        # Hip√≥teses
        if re.search(r'hip√≥tese.*principal|main.*hypothesis', content, re.IGNORECASE):
            score += 3
        else:
            feedback.append("‚ùå Hip√≥teses principais n√£o definidas")
            
        # Plano de aprendizado
        if re.search(r'plano.*aprendizado|learning.*plan', content, re.IGNORECASE):
            score += 2
        else:
            feedback.append("‚ùå Plano de aprendizado n√£o claro")
            
        # Formata√ß√£o
        checked, total = self.count_checkboxes(content)
        if checked / total > 0.7:
            score += 2
        else:
            feedback.append(f"‚ùå Apenas {checked}/{total} checkboxes preenchidos")
            
        return score, feedback
        
    def run_validation(self):
        """Executa valida√ß√£o completa"""
        print("üîç Iniciando valida√ß√£o do PRD...")
        
        content = self.load_prd()
        
        # Executa valida√ß√µes por se√ß√£o
        sections = [
            ("Problema e Oportunidade", self.validate_problem_section, 15),
            ("Personas e JTBD", self.validate_personas_section, 15),
            ("North Star Metric", self.validate_north_star, 10),
            ("MVP e Funcionalidades", self.validate_mvp_section, 15),
            ("M√©tricas de Sucesso", self.validate_metrics_section, 10),
            ("Riscos e Mitiga√ß√µes", self.validate_risks_section, 10),
            ("Timeline e Recursos", self.validate_timeline_section, 10),
            ("Qualidade e Completude", self.validate_quality_section, 10)
        ]
        
        total_score = 0
        max_score = 0
        all_feedback = []
        
        for section_name, validator, section_max in sections:
            score, feedback = validator(content)
            total_score += score
            max_score += section_max
            
            print(f"\nüìã {section_name}: {score}/{section_max}")
            if feedback:
                all_feedback.extend(feedback)
                for item in feedback:
                    print(f"   {item}")
            else:
                print("   ‚úÖ Se√ß√£o validada")
        
        # Calcula percentual
        percentage = (total_score / max_score) * 100
        
        # Determina status
        if percentage >= 90:
            status = "‚úÖ Excelente"
            recommendation = "Pronto para desenvolvimento"
        elif percentage >= 80:
            status = "‚úÖ Bom"
            recommendation = "Pequenos ajustes recomendados"
        elif percentage >= 70:
            status = "‚ö†Ô∏è Aceit√°vel"
            recommendation = "Revis√µes recomendadas"
        elif percentage >= 60:
            status = "‚ùå Insuficiente"
            recommendation = "Revis√£o obrigat√≥ria"
        else:
            status = "‚ùå Cr√≠tico"
            recommendation = "Refazer PRD"
        
        # Gera relat√≥rio
        print(f"\n{'='*50}")
        print(f"üìä RELAT√ìRIO DE VALIDA√á√ÉO")
        print(f"{'='*50}")
        print(f"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"PRD: {self.prd_path}")
        print(f"Score: {total_score}/{max_score} ({percentage:.1f}%)")
        print(f"Status: {status}")
        print(f"Recomenda√ß√£o: {recommendation}")
        
        if all_feedback:
            print(f"\nüîß ITENS CR√çTICOS PENDENTES:")
            for i, item in enumerate(all_feedback, 1):
                print(f"   {i}. {item}")
        
        # Salva relat√≥rio
        self.save_validation_report(total_score, max_score, percentage, status, all_feedback)
        
        return percentage >= self.min_score
        
    def save_validation_report(self, score, max_score, percentage, status, feedback):
        """Salva relat√≥rio de valida√ß√£o"""
        report_path = self.base_dir / "docs" / "01-produto" / "validation-report.md"
        
        report_content = f"""# Relat√≥rio de Valida√ß√£o de PRD

## Resultado
- **Data:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Score:** {score}/{max_score} ({percentage:.1f}%)
- **Status:** {status}
- **Threshold M√≠nimo:** {self.min_score}%

## Itens Cr√≠ticos Pendentes
"""
        
        if feedback:
            for i, item in enumerate(feedback, 1):
                report_content += f"{i}. {item}\n"
        else:
            report_content += "Nenhum item cr√≠tico pendente.\n"
        
        report_content += f"""
## Recomenda√ß√µes
"""
        
        if percentage >= 90:
            report_content += "- PRD est√° pronto para avan√ßar para a pr√≥xima fase\n"
            report_content += "- Iniciar Engenharia de Requisitos\n"
        elif percentage >= 70:
            report_content += "- Realizar ajustes nos itens cr√≠ticos\n"
            report_content += "- Revalidar ap√≥s corre√ß√µes\n"
        else:
            report_content += "- Revisar completamente o PRD\n"
            report_content += "- Focar nas se√ß√µes com score baixo\n"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            print(f"\nüìÑ Relat√≥rio salvo em: {report_path}")
        except Exception as e:
            print(f"‚ùå Erro ao salvar relat√≥rio: {e}")

def main():
    parser = argparse.ArgumentParser(description="Validador de PRD - Maestro Skills")
    parser.add_argument("--base-dir", help="Diret√≥rio base do projeto")
    parser.add_argument("--prd-path", help="Caminho customizado do PRD")
    parser.add_argument("--min-score", type=int, default=70, help="Score m√≠nimo para aprova√ß√£o")
    
    args = parser.parse_args()
    
    validator = PRDValidator(args.base_dir)
    
    if args.prd_path:
        validator.prd_path = Path(args.prd_path)
    
    if args.min_score:
        validator.min_score = args.min_score
    
    # Executa valida√ß√£o
    if validator.run_validation():
        print("\nüéâ PRD VALIDADO COM SUCESSO!")
        print("‚úÖ Pronto para avan√ßar para a pr√≥xima fase")
        sys.exit(0)
    else:
        print("\n‚ùå PRD N√ÉO ATINGIU SCORE M√çNIMO")
        print("üîß Realize as corre√ß√µes sugeridas e valide novamente")
        sys.exit(1)

if __name__ == "__main__":
    main()