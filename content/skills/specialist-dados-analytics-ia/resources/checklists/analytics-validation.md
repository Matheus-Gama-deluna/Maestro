# ‚úÖ Checklist de Valida√ß√£o - Dados e Analytics

## Vis√£o Geral

Checklist automatizado para valida√ß√£o da qualidade e completude de pipelines de dados, modelagem dimensional e dashboards analytics.

## üéØ Crit√©rios de Valida√ß√£o

### 1. Fontes de Dados (20 pontos)

#### ‚úÖ Fontes Mapeadas (5 pontos)
- [ ] Todas as fontes de dados identificadas e documentadas
- [ ] Conex√µes testadas e validadas
- [ ] Credenciais seguras e armazenadas adequadamente
- [ ] Respons√°veis por fonte definidos
- [ ] SLAs de disponibilidade estabelecidos

#### ‚úÖ Schema Validado (5 pontos)
- [ ] Schema de entrada validado e documentado
- ] Tipos de dados corretos para cada campo
- ] Chaves prim√°rias e estrangeiras definidas
- ] Constraints e regras de integridade implementadas
- ] Versionamento do schema controlado

#### ‚úÖ Qualidade da Fonte (5 pontos)
- [ ] Confiabilidade da fonte avaliada (Alta/M√©dia/Baixa)
- ] Frequ√™ncia de atualiza√ß√£o documentada
- ] Volume de dados estimado corretamente
- ] Hist√≥rico de disponibilidade analisado
- ] Mecanismos de backup definidos

#### ‚úÖ Acesso e Seguran√ßa (5 pontos)
- [ ] Permiss√µes de acesso configuradas
- ] Autentica√ß√£o implementada (OAuth/API Keys/etc)
- ] Criptografia de dados sens√≠veis
- ] Logs de acesso configurados
- ] Auditoria de acesso habilitada

### 2. Pipeline ETL/ELT (25 pontos)

#### ‚úÖ Extra√ß√£o (8 pontos)
- [ ] M√©todo de extra√ß√£o definido (Full/Incremental/CDC)
- [ ] Tratamento de erros implementado
- [ ] Logs detalhados do processo
- [ ] Monitoramento de performance ativo
- [ ] Recupera√ß√£o de falhas configurada
- [ ] Idempot√™ncia garantida
- [ ] Valida√ß√£o de dados na origem
- [ ] Concorr√™ncia controlada

#### ‚úÖ Transforma√ß√£o (9 pontos)
- [ ] Regras de limpeza implementadas
- ] Valida√ß√£o de qualidade aplicada
- ] Enriquecimento de dados realizado
- ] Normaliza√ß√£o e padroniza√ß√£o aplicada
- ] Deduplica√ß√£o implementada
- ] Agrega√ß√µes corretas conforme neg√≥cio
- ] Transforma√ß√µes testadas unitariamente
- ] Documenta√ß√£o de transforma√ß√µes
- ] Performance otimizada

#### ‚úÖ Carga (8 pontos)
- [ ] Destino configurado corretamente
- [ ] Schema do destino validado
- [ ] Estrat√©gia de particionamento implementada
- ] M√©todo de atualiza√ß√£o definido (Insert/Update/Upsert)
- ] Performance de carga otimizada
- ] √çndices criados adequadamente
- ] Backup de dados configurado
- ] Rollback implementado

### 3. Modelagem Dimensional (20 pontos)

#### ‚úÖ Design Dimensional (7 pontos)
- [ ] Star Schema implementado corretamente
- [ ] Tabelas de fato identificadas
- [ ] Dimens√µes identificadas
- [ ] Granularidade definida para cada fato
- [ ] Relacionamentos corretos entre tabelas
- [ ] Surrogate keys implementadas
- [ ] Slowly Changing Dimensions planejadas

#### ‚úÖ Qualidade do Modelo (7 pontos)
- [ ] Normaliza√ß√£o aplicada (3NF)
[ ] Desnormaliza√ß√£o justificada (performance)
[ ] Chaves prim√°rias definidas
[ ] Chaves estrangeiras implementadas
[ ] Integridade referencial garantida
[ ] Consist√™ncia de dados mantida
[ ] Documenta√ß√£o do modelo completa

#### ‚úÖ Performance do Modelo (6 pontos)
- [ ] √çndices criados para queries cr√≠ticas
[ ] Particionamento estrat√©gico implementado
[ ] Consultas otimizadas
[ ] Materialized views usadas quando apropriado
[ ] Estat√≠sticas de tabelas atualizadas
[ ] Performance de queries aceit√°vel (< 10s)

### 4. Qualidade de Dados (15 pontos)

#### ‚úÖ Completude (4 pontos)
[ ] Taxa de nulidade em campos obrigat√≥rios ‚â• 98%
[ ] Percentual de registros completos ‚â• 95%
[ ] Campos cr√≠ticos sempre preenchidos
[ ] Valida√ß√£o de completude automatizada

#### ‚úÖ Acur√°cia (4 pontos)
[ ] Taxa de acur√°cia ‚â• 99%
[ ] Valida√ß√£o cruzada com fontes originais
[ ] Testes de precis√£o implementados
[ ] Discrep√¢ncias identificadas e corrigidas

#### ‚úÖ Consist√™ncia (4 pontos)
[ ] Integridade referencial mantida
[ ] Formatos consistentes entre fontes
[ ] Valores dentro de dom√≠nios esperados
[ ] Regras de neg√≥cio validadas

#### ‚úÖ Atualiza√ß√£o (3 pontos)
[ ] Freshness dos dados dentro do SLA
[ ] Timestamps de √∫ltima atualiza√ß√£o
[ ] Alertas para dados obsoletos
[ ] Processo de atualiza√ß√£o automatizado

### 5. Dashboards e Visualiza√ß√£o (20 pontos)

#### ‚úÖ Funcionalidade (8 pontos)
- [ ] KPIs principais exibidos corretamente
[ ] F√≥rmulas de c√°lculo implementadas
[ ] Filtros interativos funcionando
- ] Drill-down dispon√≠vel onde aplic√°vel
[ ] Compara√ß√£o com per√≠odos anteriores
- ] Exporta√ß√£o de dados dispon√≠vel
[ ] Responsividade em diferentes dispositivos
[ ] Acessibilidade (WCAG 2.1) implementada

#### ‚úÖ Performance (6 pontos)
[ ] Tempo de carregamento < 5 segundos (P95)
[ ] Tempo de resposta a filtros < 1 segundo
[ ] N√∫mero de usu√°rios simult√¢neos suportado
[ ] Uso eficiente de cache
[ ] Otimiza√ß√£o de consultas
[ ] M√©tricas de performance monitoradas

#### ‚úÖ Usabilidade (6 pontos)
- [ ] Interface intuitiva e f√°cil de usar
- **Navega√ß√£o clara** entre se√ß√µes
- **Legendas e r√≥tulos** informativos
- **Cores e formata√ß√£o** consistentes
- **Ajuda contextual** dispon√≠vel
- **Feedback visual** para a√ß√µes
- **Treinamento m√≠nimo** necess√°rio

### 6. Monitoramento e Alertas (10 pontos)

#### ‚úÖ Monitoramento (5 pontos)
[ ] M√©tricas de pipeline coletadas
[ ] Performance de queries monitorada
[ ] Qualidade de dados rastreada
[ ] Disponibilidade dos servi√ßos verificada
[ ] Dashboard de opera√ß√µes funcionando

#### ‚úÖ Alertas (5 pontos)
- [ ] Alertas cr√≠ticas configuradas
- ] Canais de notifica√ß√£o definidos
- ] Escalonamento de alertas implementado
- **Falsos positivos minimizados**
- ] Processo de resposta a incidentes

---

## üìä C√°lculo de Score

### F√≥rmula
```
Score Total = Œ£ (Pontos Obtidos / Pontos Poss√≠veis) √ó 100
```

### Thresholds
- **Aprova√ß√£o Autom√°tica**: ‚â• 80 pontos
- **Revis√£o Manual**: 60-79 pontos
- **Reconfigura√ß√£o Obrigat√≥ria**: < 60 pontos

### Exemplo de C√°lculo
```
Fontes de Dados: 18/20 (90%)
Pipeline ETL: 22/25 (88%)
Modelagem Dimensional: 17/20 (85%)
Qualidade de Dados: 14/15 (93%)
Dashboards: 18/20 (90%)
Monitoramento: 9/10 (90%)

Score Total = (18+22+17+14+18+9) / (20+25+20+15+20+10) √ó 100
Score Total = 98 / 110 √ó 100 = 89 pontos ‚úÖ
```

## üîç Valida√ß√£o Autom√°tica

### Checks de Sintaxe
```python
def validate_pipeline_structure(pipeline_config):
    """Valida estrutura do pipeline"""
    required_components = [
        "sources",
        "extract",
        "transform",
        "load",
        "monitoring"
    ]
    
    for component in required_components:
        if component not in pipeline_config:
            return False, f"Componente obrigat√≥rio ausente: {component}"
    
    return True, "Estrutura v√°lida"
```

### Checks de Qualidade
```python
def validate_data_quality(data_warehouse):
    """Valida√ß√£o autom√°tica de qualidade de dados"""
    issues = []
    
    # Verificar completude
    null_checks = """
    SELECT 
        table_name,
        COUNT(*) as total,
        COUNT(CASE WHEN critical_field IS NULL THEN 1 END) as nulos,
        (COUNT(*) - COUNT(CASE WHEN critical_field IS NULL THEN 1 END)) * 100.0 / COUNT(*) as completude
    FROM data_quality_metrics 
    WHERE validation_date = CURRENT_DATE
    GROUP BY table_name
    """
    
    # Verificar unicidade
    duplicate_checks = """
    SELECT 
        table_name,
        COUNT(*) as total,
        COUNT(DISTINCT unique_key) as unicos,
        COUNT(*) - COUNT(DISTINCT unique_key) as duplicatas
    FROM data_quality_metrics
    WHERE validation_date = CURRENT_DATE
    GROUP BY table_name
    """
    
    # Verificar atualiza√ß√£o
    freshness_checks = """
    SELECT 
        table_name,
        MAX(last_updated) as ultima_atualizacao,
        CURRENT_TIMESTAMP - MAX(last_updated) as idade_dados
    FROM data_quality_metrics
    GROUP BY table_name
    """
    
    return {
        "null_checks": null_checks,
        "duplicate_checks": duplicate_checks,
        "freshness_checks": freshness_checks,
        "issues": issues
    }
```

### Checks de Performance
```python
def validate_dashboard_performance(dashboard_metrics):
    """Valida√ß√£o de performance do dashboard"""
    issues = []
    
    # Verificar tempo de carregamento
    load_time_check = dashboard_metrics.get("p95_load_time", 0)
    if load_time_check > 5000:  # 5 segundos
        issues.append(f"Tempo de carregamento muito alto: {load_time_check}ms")
    
    # Verificar taxa de erro
    error_rate = dashboard_metrics.get("error_rate", 0)
    if error_rate > 0.01:  # 1%
        issues.append(f"Taxa de erro alta: {error_rate:.2%}")
    
    # Verificar concorr√™ncia
    concurrent_users = dashboard_metrics.get("concurrent_users", 0)
    if concurrent_users < 10:
        issues.append(f"Baixa capacidade de usu√°rios simult√¢neos: {concurrent_users}")
    
    return {
        "load_time": load_time_check,
        "error_rate": error_rate,
        "concurrent_users": concurrent_users,
        "issues": issues
    }
```

## üîÑ Fluxo de Valida√ß√£o

### 1. Valida√ß√£o Inicial
```python
async def validate_analytics_feature(feature_content):
    """Valida√ß√£o inicial da feature de analytics"""
    
    # Valida√ß√£o de estrutura
    structure_valid, structure_msg = validate_feature_structure(feature_content)
    if not structure_valid:
        return {"success": False, "error": structure_msg}
    
    # Valida√ß√£o de conte√∫do
    content_valid, content_msg = validate_feature_content(feature_content)
    if not content_valid:
        return {"success": False, "error": content_msg}
    
    # Valida√ß√£o de l√≥gica
    logic_valid, logic_issues = validate_feature_logic(feature_content)
    if not logic_valid:
        return {"success": False, "errors": logic_issues}
    
    return {"success": True, "message": "Valida√ß√£o inicial aprovada"}
```

### 2. C√°lculo de Score
```python
def calculate_analytics_score(feature_content):
    """Calcula score de qualidade da feature"""
    
    score_breakdown = {
        "data_sources": validate_data_sources_score(feature_content),
        "pipeline": validate_pipeline_score(feature_content),
        "data_modeling": validate_modeling_score(feature_content),
        "data_quality": validate_data_quality_score(feature_content),
        "dashboards": validate_dashboards_score(feature_content),
        "monitoring": validate_monitoring_score(feature_content)
    }
    
    total_score = sum(score_breakdown.values())
    max_score = 110  # 20+25+20+15+20+10
    
    return {
        "total_score": total_score,
        "max_score": max_score,
        "percentage": (total_score / max_score) * 100,
        "breakdown": score_breakdown,
        "can_proceed": total_score >= 80
    }
```

### 3. Gera√ß√£o de Relat√≥rio
```python
def generate_validation_report(feature_content, score_result):
    """Gera relat√≥rio detalhado de valida√ß√£o"""
    
    report = {
        "validation_timestamp": datetime.now().isoformat(),
        "feature_id": feature_content.get("id", "unknown"),
        "score": score_result,
        "status": "approved" if score_result["can_proceed"] else "rejected",
        "recommendations": generate_recommendations(feature_content, score_result),
        "next_actions": generate_next_actions(score_result)
    }
    
    return report
```

## üìä M√©tricas de Valida√ß√£o

### KPIs do Processo
- **Tempo m√©dio de valida√ß√£o:** < 2 minutos
- **Taxa de aprova√ß√£o:** > 85%
- **Score m√©dio qualidade:** > 85 pontos
- **Falsos positivos:** < 5%

### M√©tricas de Qualidade
- **Coverage de valida√ß√£o:** 100%
- **Precis√£o das recomenda√ß√µes:** > 90%
- **Tempo de corre√ß√£o:** < 10 minutos
- **Satisfa√ß√£o do usu√°rio:** > 95%

---

## üîÑ Valida√ß√£o Cont√≠nua

### Monitoramento de Drift
```python
def detect_analytics_drift(current_state, expected_state):
    """Detecta drift nos dados e analytics"""
    
    drift_report = {
        "timestamp": datetime.now().isoformat(),
        "drift_detected": False,
        "drifts": []
    }
    
    # Comparar m√©tricas atuais vs esperadas
    for metric in expected_state:
        if current_state.get(metric, 0) != expected_state[metric]:
            drift_report["drift_detected"] = True
            drift_report["drifts"].append({
                "metric": metric,
                "expected": expected_state[metric],
                "current": current_state.get(metric, 0),
                "deviation": current_state.get(metric, 0) - expected_state[metric]
            })
    
    return drift_report
```

### Valida√ß√£o de Compliance
```python
def validate_compliance_requirements(feature_content):
    """Valida requisitos de compliance"""
    
    compliance_checks = {
        "lgpd": {
            "data_anonymization": feature_content.get("anonymize_pii", False),
            "retention_policy": feature_content.get("retention_days", 0) >= 365,
            "access_control": feature_content.get("rbac_enabled", False)
        },
        "pci_dss": {
            "encryption_at_rest": feature_content.get("encryption_enabled", False),
            "audit_logs": feature_content.get("audit_logging", False),
            "network_security": feature_content.get("firewall_enabled", False)
        },
        "sox": {
            "financial_reporting": feature_content.get("financial_controls", False),
            "change_management": feature_content.get("change_control", False),
            "internal_controls": feature_content.get("internal_audits", False)
        }
    }
    
    compliance_score = 0
    total_checks = len(compliance_checks) * 3  # 3 checks por framework
    
    for framework, checks in compliance_checks.items():
        framework_score = sum(checks.values()) / len(checks) * 100
        compliance_score += framework_score
    
    return {
        "compliance_score": compliance_score / total_checks * 100,
        "checks": compliance_checks,
        "compliant": compliance_score >= 80
    }
```

## üìã Recomenda√ß√µes Autom√°ticas

### Para Score < 80
```python
def generate_recommendations(feature_content, score_result):
    """Gera recomenda√ß√µes baseadas no score e feature"""
    
    recommendations = []
    
    # Recomenda√ß√µes baseadas no score
    if score_result["score"] < 60:
        recommendations.append("‚ö†Ô∏è Score baixo (< 60). Reconfigura√ß√£o obrigat√≥ria recomendada.")
    elif score_result["score"] < 80:
        recommendations.append("‚ö†Ô∏è Score m√©dio (60-79). Revisar e corrigir issues cr√≠ticos.")
    else:
        recommendations.append("‚úÖ Score bom (‚â• 80). Configura√ß√£o aprovada.")
    
    # Recomenda√ß√µes baseadas no breakdown
    breakdown = score_result["breakdown"]
    
    if breakdown["data_sources"] < 15:
        recommendations.append("üîó Complete o mapeamento de fontes de dados")
    
    if breakdown["pipeline"] < 20:
        recommendations.append("üîÑ Implemente pipeline ETL/ELT completo")
    
    if breakdown["data_modeling"] < 15:
        recommendations.append("üìä Refine a modelagem dimensional")
    
    if breakdown["data_quality"] < 12:
        recommendations.append("üîç Melhore a qualidade dos dados")
    
    if breakdown["dashboards"] < 15:
        recommendations.append("üìà Otimize os dashboards")
    
    if breakdown["monitoring"] < 8:
        recommendations.append("üìä Configure monitoramento e alertas")
    
    return recommendations
```

## üîÑ Valida√ß√£o de Implementa√ß√£o no MCP

### Fun√ß√£o de Valida√ß√£o
```python
async def validate_analytics_quality(params):
    """Fun√ß√£o MCP para valida√ß√£o automatizada"""
    
    feature_content = params["feature_content"]
    validation_level = params.get("validation_level", "complete")
    
    # Valida√ß√£o inicial
    initial_validation = await validate_analytics_feature(feature_content)
    if not initial_validation["success"]:
        return initial_validation
    
    # C√°lculo de score
    score_result = calculate_analytics_score(feature_content)
    
    # Valida√ß√£o de compliance
    compliance_validation = validate_compliance_requirements(feature_content)
    
    # Gera√ß√£o de relat√≥rio
    report = generate_validation_report(feature_content, score_result)
    
    return {
        "success": True,
        "validation_report": report,
        "score": score_result,
        "can_proceed": score_result["can_proceed"],
        "compliance_status": compliance_validation,
        "next_actions": generate_next_actions(score_result)
    }
```

Este checklist garante qualidade consistente e valida√ß√£o automatizada para todas as configura√ß√µes de analytics.
