# Prompt: Estrat√©gias de Cache

> **Prioridade**: üü° M√âDIA  
> **Aplic√°vel a**: APIs com alta carga, dados lidos frequentemente

---

## Prompt Base: Projetar Cache

```text
Atue como engenheiro de performance.

Tenho um sistema com:
- Stack: [ex. Node.js + PostgreSQL + Redis]
- Tr√°fego: [ex. 1000 req/s, 80% leitura, 20% escrita]
- Dados: [ex. cat√°logo de 50k produtos, users sessions, configura√ß√µes]
- Lat√™ncia atual: [ex. p95 = 500ms]
- Meta: [ex. p95 < 100ms]

Para cada tipo de dado, recomende:

1. **Padr√£o de Cache**
   - Cache-aside, write-through, read-through, ou combina√ß√£o
   - Justificativa

2. **TTL e Invalida√ß√£o**
   - Tempo de vida sugerido
   - Estrat√©gia de invalida√ß√£o (expl√≠cita, event-driven, TTL puro)

3. **Estrutura no Redis**
   - Tipo de dado Redis (string, hash, set, sorted set)
   - Naming convention para keys
   - Exemplos de comandos

4. **C√≥digo de Implementa√ß√£o**
   - Cache layer reutiliz√°vel
   - Decorators ou helpers
   - Tratamento de cache miss e falha do Redis

5. **M√©tricas**
   - O que monitorar
   - Alertas recomendados
```

---

## Prompt: Cache para Endpoint Espec√≠fico

```text
Tenho este endpoint que √© lento:
[COLE C√ìDIGO DO ENDPOINT]

M√©tricas atuais:
- Lat√™ncia: [ex. p95 = 800ms]
- Chamadas/dia: [ex. 100k]
- Taxa de mudan√ßa dos dados: [ex. atualizam 1x por hora]

Gere:
1. An√°lise do que pode ser cacheado
2. Implementa√ß√£o com cache-aside
3. Estrat√©gia de invalida√ß√£o
4. C√≥digo refatorado
5. Testes para validar cache hit/miss
```

---

## Prompt: Invalida√ß√£o de Cache

```text
Tenho o seguinte cen√°rio de cache:
- Entidades: [ex. User, Order, Product]
- Relacionamentos: [ex. User tem Orders, Order tem Products]
- Caches atuais: [ex. user:123, user:123:orders, product:456]

Quando um User √© atualizado, preciso invalidar: [DESCREVA]

Projete uma estrat√©gia de invalida√ß√£o que:
1. Garanta consist√™ncia
2. Minimize invalida√ß√µes desnecess√°rias
3. Use eventos/pub-sub se ben√©fico
4. Documente quais eventos afetam quais caches
```

---

## Prompt: Cache Multi-Layer

```text
Quero implementar cache em m√∫ltiplas camadas:
1. Browser/CDN (edge)
2. Application (in-memory)
3. Distributed (Redis)
4. Database (query cache)

Para estes endpoints:
[LISTE ENDPOINTS E CARACTER√çSTICAS]

Gere:
1. Estrat√©gia por camada
2. Headers HTTP para cache de browser/CDN
3. C√≥digo para cache in-memory + Redis
4. Quando usar cada camada
5. Como invalidar coordenadamente
```

---

## Prompt: Resolver Cache Stampede

```text
Estou tendo problemas de cache stampede:
- Cen√°rio: [ex. muitos requests simult√¢neos no cache miss]
- Impacto: [ex. banco sobrecarrega, timeout em cascata]

Stack: [DESCREVA]

Implemente:
1. Lock de requisi√ß√£o √∫nica (singleflight)
2. Probabilistic early expiration
3. Fallback para stale data durante refresh
4. C√≥digo completo com testes
```

---

## Exemplo: Cache Layer Gen√©rico

```typescript
// src/cache/cacheLayer.ts
import Redis from 'ioredis';

interface CacheOptions {
  ttl?: number;           // segundos
  staleWhileRevalidate?: boolean;
  lockTimeout?: number;   // ms
}

class CacheLayer {
  private redis: Redis;
  private locks = new Map<string, Promise<any>>();
  
  constructor(redis: Redis) {
    this.redis = redis;
  }

  async get<T>(
    key: string, 
    fetcher: () => Promise<T>, 
    options: CacheOptions = {}
  ): Promise<T> {
    const { ttl = 3600, staleWhileRevalidate = false, lockTimeout = 5000 } = options;

    // 1. Tentar cache
    const cached = await this.redis.get(key);
    if (cached) {
      const data = JSON.parse(cached);
      
      // SWR: retornar stale e atualizar em background
      if (staleWhileRevalidate && this.isNearExpiry(key)) {
        this.refreshInBackground(key, fetcher, ttl);
      }
      
      return data;
    }

    // 2. Prevenir stampede com lock
    if (this.locks.has(key)) {
      return this.locks.get(key);
    }

    // 3. Buscar com timeout
    const promise = this.fetchWithLock(key, fetcher, ttl, lockTimeout);
    this.locks.set(key, promise);
    
    try {
      return await promise;
    } finally {
      this.locks.delete(key);
    }
  }

  async invalidate(key: string): Promise<void> {
    await this.redis.del(key);
  }

  async invalidatePattern(pattern: string): Promise<void> {
    const keys = await this.redis.keys(pattern);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }
  }

  private async fetchWithLock<T>(
    key: string, 
    fetcher: () => Promise<T>, 
    ttl: number,
    timeout: number
  ): Promise<T> {
    const lockKey = `lock:${key}`;
    const lockAcquired = await this.redis.set(lockKey, '1', 'PX', timeout, 'NX');
    
    try {
      const data = await fetcher();
      await this.redis.setex(key, ttl, JSON.stringify(data));
      return data;
    } finally {
      await this.redis.del(lockKey);
    }
  }

  private async isNearExpiry(key: string): Promise<boolean> {
    const ttl = await this.redis.ttl(key);
    return ttl < 60; // √∫ltimo minuto
  }

  private async refreshInBackground<T>(
    key: string, 
    fetcher: () => Promise<T>, 
    ttl: number
  ): Promise<void> {
    // Fire and forget
    fetcher()
      .then(data => this.redis.setex(key, ttl, JSON.stringify(data)))
      .catch(err => console.error(`Background refresh failed for ${key}:`, err));
  }
}

// Uso
const cache = new CacheLayer(redis);

const user = await cache.get(
  `user:${userId}`,
  () => db.users.findById(userId),
  { ttl: 300, staleWhileRevalidate: true }
);
```

---

## Checklist

- [ ] Padr√£o de cache escolhido para cada tipo de dado
- [ ] TTLs definidos e documentados
- [ ] Invalida√ß√£o implementada para opera√ß√µes de escrita
- [ ] Prote√ß√£o contra stampede
- [ ] Monitoramento de hit rate
- [ ] Fallback se Redis indispon√≠vel
- [ ] Testes de cache hit, miss, e invalida√ß√£o

---

## Refer√™ncias

Consulte: [Guia de Estrat√©gias de Cache](../03-guias/Guia%20de%20Estrat√©gias%20de%20Cache.md)
